# technical_rag_system
Proyecto de RAG  y agente de generaci√≥n de qa para finetunning
# Technical Documentation RAG System

<div align="center">

![Python](https://img.shields.io/badge/python-v3.8+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Status](https://img.shields.io/badge/status-active-success.svg)

Sistema avanzado de Recuperaci√≥n Aumentada por Generaci√≥n (RAG) especializado en el procesamiento inteligente de documentaci√≥n t√©cnica en PDF, con capacidades multimodales y generaci√≥n autom√°tica de datasets Q&A.

</div>

## üöÄ Caracter√≠sticas Principales

### üìÑ Procesamiento de Documentos
- **An√°lisis Adaptativo**: Detecta autom√°ticamente el tipo de documento (t√©cnico, texto, escaneado, mixto) y aplica la estrategia √≥ptima
- **Extracci√≥n Multimodal**: 
  - ‚úÖ Texto con chunking inteligente y preservaci√≥n de contexto
  - ‚úÖ Tablas con estructura preservada (exportaci√≥n a CSV)
  - ‚úÖ Im√°genes raster embebidas
  - ‚úÖ Diagramas t√©cnicos renderizados con alta calidad
  - ‚úÖ OCR autom√°tico para documentos escaneados

### üîç Sistema de B√∫squeda
- **B√∫squeda H√≠brida**: Combina b√∫squeda vectorial sem√°ntica con b√∫squeda por palabras clave
- **Almacenamiento Dual**: SQLite para metadatos estructurados y ChromaDB para embeddings vectoriales
- **Indexaci√≥n Inteligente**: √çndices optimizados por manual, p√°gina y secci√≥n

### ü§ñ Generaci√≥n de Q&A
- **Dataset Autom√°tico**: Generaci√≥n de 21,778+ pares pregunta-respuesta de alta calidad
- **M√∫ltiples Tipos**: Preguntas factuales, de s√≠ntesis, causales, de aplicaci√≥n y an√°lisis
- **Validaci√≥n de Calidad**: Filtrado autom√°tico y scoring de relevancia
- **Soporte Multi-chunk**: Preguntas que integran informaci√≥n de m√∫ltiples fuentes

## üìã Requisitos del Sistema

### Hardware
- **RAM**: 8GB m√≠nimo (16GB recomendado)
- **Almacenamiento**: 10GB+ espacio libre
- **CPU**: 4+ cores recomendados para procesamiento paralelo

### Software
- Python 3.8+
- Sistema operativo: macOS, Linux, Windows
- Java (opcional, para extracci√≥n avanzada de tablas)
- Tesseract OCR (opcional, para documentos escaneados)

## üîß Instalaci√≥n

### 1. Clonar el Repositorio

```bash
git clone https://github.com/tu-usuario/technical-rag-system.git
cd technical-rag-system
```

### 2. Configurar Entorno Virtual

```bash
python -m venv venv_rag
source venv_rag/bin/activate  # En Windows: venv_rag\Scripts\activate
```

### 3. Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 4. Instalar Dependencias del Sistema (Opcional)

**Tesseract OCR** (para documentos escaneados):
```bash
# macOS
brew install tesseract

# Ubuntu/Debian
sudo apt-get install tesseract-ocr tesseract-ocr-spa

# Windows
# Descargar desde: https://github.com/UB-Mannheim/tesseract/wiki
```

### 5. Configurar Variables de Entorno

```bash
cp .env.example .env
# Editar .env con tu API key de OpenAI (para generaci√≥n Q&A)
```

### 6. Inicializar el Sistema

```bash
python scripts/init_system.py
```

## üìñ Uso R√°pido

### Procesar Manuales PDF

```bash
# Procesar todos los PDFs en un directorio
python scripts/process_manuals_sqlite.py --pdf-dir data/raw_pdfs/

# Procesar un PDF espec√≠fico con metadatos
python scripts/process_manuals_sqlite.py --single-pdf manual.pdf \
  --manufacturer "Beckhoff" --model "AX5000" --embeddings
```

### Construir Base de Datos Vectorial

```bash
# Construir base vectorial completa
python scripts/build_vectordb_sqlite.py

# Ver estad√≠sticas
python scripts/build_vectordb_sqlite.py --stats
```

### Generar Dataset Q&A

```bash
cd qa_generator
python process_all_chunks_v4.py --model gpt-3.5-turbo --batch-size 3
```

## üìÅ Estructura del Proyecto

```
technical-rag-system/
‚îú‚îÄ‚îÄ config/                 # Configuraci√≥n del sistema
‚îÇ   ‚îî‚îÄ‚îÄ settings.py         # Par√°metros centralizados
‚îú‚îÄ‚îÄ core/                   # Componentes principales
‚îÇ   ‚îú‚îÄ‚îÄ embedding_pipeline.py
‚îÇ   ‚îú‚îÄ‚îÄ hybrid_search.py
‚îÇ   ‚îî‚îÄ‚îÄ intelligent_chunking.py
‚îú‚îÄ‚îÄ data/                   # Almacenamiento de datos
‚îÇ   ‚îú‚îÄ‚îÄ raw_pdfs/          # PDFs originales
‚îÇ   ‚îú‚îÄ‚îÄ processed/         # Contenido procesado por manual
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Manual_*/      # Carpeta por cada manual
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ images/    # Im√°genes extra√≠das
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ diagrams/  # Diagramas renderizados
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ tables/    # Tablas en CSV
‚îÇ   ‚îú‚îÄ‚îÄ vectordb/          # Base vectorial ChromaDB
‚îÇ   ‚îî‚îÄ‚îÄ sqlite/            # Base de datos SQLite
‚îú‚îÄ‚îÄ database/              # Gesti√≥n de base de datos
‚îÇ   ‚îî‚îÄ‚îÄ sqlite_manager.py
‚îú‚îÄ‚îÄ extractors/            # Extractores de contenido
‚îÇ   ‚îú‚îÄ‚îÄ adaptive_processor.py
‚îÇ   ‚îú‚îÄ‚îÄ pdf_extractor.py
‚îÇ   ‚îî‚îÄ‚îÄ table_extractor.py
‚îú‚îÄ‚îÄ qa_generator/          # Generaci√≥n de datasets Q&A
‚îÇ   ‚îú‚îÄ‚îÄ qa_generator.py
‚îÇ   ‚îú‚îÄ‚îÄ chunk_manager.py
‚îÇ   ‚îî‚îÄ‚îÄ prompt_templates.py
‚îú‚îÄ‚îÄ scripts/               # Scripts ejecutables
‚îÇ   ‚îú‚îÄ‚îÄ init_system.py
‚îÇ   ‚îú‚îÄ‚îÄ process_manuals_sqlite.py
‚îÇ   ‚îî‚îÄ‚îÄ build_vectordb_sqlite.py
‚îî‚îÄ‚îÄ vectorstore/           # Gesti√≥n de vectores
    ‚îú‚îÄ‚îÄ vector_manager.py
    ‚îî‚îÄ‚îÄ retrieval.py
```

## üóÑÔ∏è Base de Datos

### Esquema SQLite

El sistema utiliza las siguientes tablas principales:

- **manuals**: Informaci√≥n de manuales procesados
- **content_blocks**: Bloques de texto extra√≠dos con posici√≥n
- **content_chunks**: Fragmentos optimizados para b√∫squeda
- **images**: Metadatos de im√°genes y diagramas
- **tables**: Informaci√≥n de tablas extra√≠das
- **document_analysis**: An√°lisis del tipo de documento
- **processing_logs**: Historial de procesamiento

## üî¨ Flujo de Procesamiento

```mermaid
graph LR
    A[PDF Input] --> B[An√°lisis de Documento]
    B --> C{Tipo de Doc}
    C -->|T√©cnico| D[Extracci√≥n Especializada]
    C -->|Escaneado| E[OCR + Extracci√≥n]
    C -->|Mixto| F[Procesamiento H√≠brido]
    D --> G[Chunking Inteligente]
    E --> G
    F --> G
    G --> H[Generaci√≥n Embeddings]
    H --> I[Indexaci√≥n]
    I --> J[Base Vectorial]
    G --> K[Generaci√≥n Q&A]
    K --> L[Dataset JSONL]
```

## üìä Rendimiento

### Estad√≠sticas de Procesamiento Real

- **Documentos procesados**: 3 manuales t√©cnicos complejos
- **Total chunks generados**: 4,558
- **Im√°genes extra√≠das**: 1,611 (raster + diagramas)
- **Tablas procesadas**: 1,244
- **Dataset Q&A generado**: 21,778 pares
- **Tiempo de procesamiento PDF**: ~2 horas/manual
- **Tiempo generaci√≥n Q&A**: ~48 horas (con rate limits)

### Optimizaci√≥n de Memoria

```python
# En config/settings.py
BATCH_SIZE = 32        # Ajustar seg√∫n RAM disponible
MAX_WORKERS = 4        # Paralelismo seg√∫n CPU
CHUNK_SIZE = 512       # Tama√±o √≥ptimo de chunks
CHUNK_OVERLAP = 50     # Solapamiento para contexto
```

## üõ†Ô∏è Configuraci√≥n Avanzada

### Ajustar Modelos de Embeddings

```python
# config/settings.py
EMBEDDING_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
EMBEDDING_DIMENSION = 384
```

### Tipos de Chunks Adaptativos

```python
ADAPTIVE_CHUNK_SIZES = {
    'technical_diagram_heavy': 1024,
    'text_heavy': 512,
    'table_heavy': 768,
    'scanned': 768,
    'mixed': 512
}
```

